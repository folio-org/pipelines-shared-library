#!groovy
import org.folio.Constants
import org.folio.jenkins.PodTemplates
import org.folio.models.TerraformConfig

@Library('pipelines-shared-library') _

properties([
  buildDiscarder(logRotator(numToKeepStr: '20')),
  // disableConcurrentBuilds(),
  parameters([
    folioParameters.cluster(),
    string(name: 'INSTANCE_SHAPE', defaultValue: 'r5a.xlarge', description: 'List of EC2 shapes to be used in cluster provisioning', trim: true),
    choice(name: 'INSTANCE_TYPE', choices: ['ON_DEMAND', 'SPOT'], description: 'Select capacity type associated with the EKS Node Group. (SPOT-for testing purposes only)'),
    string(name: 'CLUSTER_MIN_SIZE', defaultValue: '2', description: 'Minimum size of node group for eks cluster', trim: true),
    string(name: 'CLUSTER_MAX_SIZE', defaultValue: '3', description: 'Maximum size of node group for eks cluster', trim: true),
    string(name: 'CLUSTER_DESIRED_SIZE', defaultValue: '2', description: 'Desired size of node group for eks cluster', trim: true),
    booleanParam(name: 'REGISTER', defaultValue: true, description: 'Register cluster in Rancher'),
    booleanParam(name: 'KUBECOST', defaultValue: true, description: 'Deploy Kubecost to cluster'),
    booleanParam(name: 'SORRY_CYPRESS', defaultValue: false, description: 'Deploy Sorry Cypress to cluster'),
    booleanParam(name: 'ENABLE_LOGGING', defaultValue: false, description: 'Deploy ELK stack to cluster'),
    booleanParam(name: 'ENABLE_MONITORING', defaultValue: true, description: 'Deploy Prometheus to cluster'),
    folioParameters.refreshParameters()
  ])
])

if (params.REFRESH_PARAMETERS) {
  currentBuild.result = 'ABORTED'
  return
}

PodTemplates podTemplates = new PodTemplates(this)
TerraformConfig tfConfig = new TerraformConfig('terraform/rancher/cluster')
  .withWorkspace(params.CLUSTER)

tfConfig.addVar('vpc_name', Constants.AWS_EKS_VPC_NAME)
tfConfig.addVar('eks_nodes_type', params.INSTANCE_TYPE)
tfConfig.addVar('asg_instance_types', params.INSTANCE_SHAPE.trim().split(',').collect { "\"${it}\"" })
tfConfig.addVar('eks_nodes_group_size', _getClusterSize())
tfConfig.addVar('admin_users', Constants.AWS_EKS_ADMIN_USERS)
tfConfig.addVar('register_in_rancher', params.REGISTER)
tfConfig.addVar('deploy_kubecost', params.KUBECOST)
tfConfig.addVar('deploy_sorry_cypress', params.SORRY_CYPRESS)
tfConfig.addVar('enable_logging', params.ENABLE_LOGGING)
tfConfig.addVar('enable_monitoring', params.ENABLE_MONITORING)

ansiColor('xterm') {
  podTemplates.rancherAgent {
    stage('Ini') {
      buildName "#${params.CLUSTER}.${env.BUILD_ID}"
    }

    stage('Checkout') {
      git(url: "${Constants.FOLIO_GITHUB_URL}/pipelines-shared-library.git",
        branch: folioTools.getPipelineBranch(),
        credentialsId: Constants.PRIVATE_GITHUB_CREDENTIALS_ID,
        poll: false)
    }

    folioTerraformFlow.manageCluster('apply', tfConfig)
  }
}

private String _getClusterSize() {
  if (params.CLUSTER_MIN_SIZE.toInteger() >= params.CLUSTER_MAX_SIZE.toInteger() ||
    params.CLUSTER_MIN_SIZE.toInteger() > params.CLUSTER_DESIRED_SIZE.toInteger() ||
    params.CLUSTER_MAX_SIZE.toInteger() < params.CLUSTER_DESIRED_SIZE.toInteger()) {
    error("Cluster size parameters are incorrect")
  }
  return writeJSON(returnText: true, json: [min_size: params.CLUSTER_MIN_SIZE, max_size: params.CLUSTER_MAX_SIZE, desired_size: params.CLUSTER_DESIRED_SIZE])
}
