#!groovy
import org.folio.Constants
import org.folio.models.InstallRequestParams
import org.folio.models.OkapiConfig
import org.folio.models.OkapiTenant
import org.folio.models.RancherNamespace
import org.folio.models.TenantUi
import org.folio.models.TerraformConfig
import org.folio.rest.GitHubUtility
import org.folio.rest_v2.Main
import org.folio.utilities.Tools
import org.jenkinsci.plugins.workflow.libs.Library

@Library('pipelines-shared-library@RANCHER-741-Jenkins-Enhancements') _

CONFIG_BRANCH = 'RANCHER-741-Jenkins-Enhancements'

properties([buildDiscarder(logRotator(numToKeepStr: '30')),
            disableConcurrentBuilds(),
            parameters([folioParameters.cluster(),
                        folioParameters.namespace(),
                        folioParameters.configType(),
                        booleanParam(name: 'CONSORTIA', defaultValue: false, description: '(Optional) Set to true to enable consortium'),
                        booleanParam(name: 'RW_SPLIT', defaultValue: false, description: '(Optional) Set to true to enable Read/Write split'),
                        folioParameters.pgType(),
                        folioParameters.kafkaType(),
                        folioParameters.opensearchType(['aws']),
                        folioParameters.s3Type(),
                        folioParameters.agent(),
                        folioParameters.refreshParameters()]),
            pipelineTriggers([parameterizedCron('''45 01 * * 1-5 %CLUSTER=folio-testing;NAMESPACE=esc-snapshot;CONFIG_TYPE=testing;CONSORTIA=true;RW_SPLIT=false;POSTGRESQL=built-in;KAFKA=built-in;OPENSEARCH=aws;S3_BUCKET=built-in;AGENT=jenkins-agent-java17''')])])

if (params.REFRESH_PARAMETERS) {
    currentBuild.result = 'ABORTED'
    return
}

String defaultTenantId = 'cs00000int'
List updateJson

TerraformConfig tfConfig = new TerraformConfig('terraform/rancher/project')
        .withWorkspace("${params.CLUSTER}-${params.NAMESPACE}")

tfConfig.addVar('rancher_cluster_name', params.CLUSTER)
tfConfig.addVar('rancher_project_name', params.NAMESPACE)
tfConfig.addVar('tenant_id', defaultTenantId)
tfConfig.addVar('pg_password', Constants.PG_ROOT_DEFAULT_PASSWORD)
tfConfig.addVar('pgadmin_password', Constants.PGADMIN_DEFAULT_PASSWORD)
tfConfig.addVar('pg_version', '12.15')
tfConfig.addVar('pg_dbname', 'folio')
tfConfig.addVar('pg_vol_size', 100)
tfConfig.addVar('pg_embedded', params.POSTGRESQL == 'built-in')
tfConfig.addVar('kafka_shared', params.KAFKA != 'built-in')
tfConfig.addVar('opensearch_shared', params.OPENSEARCH != 'built-in')
tfConfig.addVar('s3_embedded', params.S3_BUCKET == 'built-in')
tfConfig.addVar('pgadmin4', 'true')
tfConfig.addVar('enable_rw_split', params.RW_SPLIT)
tfConfig.addVar('pg_ldp_user_password', Constants.PG_LDP_DEFAULT_PASSWORD)
tfConfig.addVar('github_team_ids', folioTools.getGitHubTeamsIds("${Constants.ENVS_MEMBERS_LIST[params.NAMESPACE]},${params.MEMBERS}").collect { "\"${it}\"" })

String installJsonS3Path = "${Constants.PSQL_DUMP_BACKUPS_BUCKET_NAME}/ecs-snapshot/"

InstallRequestParams installRequestParams = new InstallRequestParams(reinstall: true)

RancherNamespace namespace = new RancherNamespace(params.CLUSTER, params.NAMESPACE)
        .withSuperTenantAdminUser()
        .withDefaultTenant(defaultTenantId)
        .withDeploymentConfigType(params.CONFIG_TYPE)

namespace.addDeploymentConfig(CONFIG_BRANCH)
namespace.setEnableRwSplit(params.RW_SPLIT)

Main main = new Main(this, namespace.generateDomain('okapi'), namespace.getSuperTenant())

ansiColor('xterm') {
    node(params.AGENT) {
        stage('Ini') {
            buildName "${tfConfig.getWorkspace()}-${env.BUILD_ID}"
            buildDescription "Config: ${params.CONFIG_TYPE}"
        }
        try {
            stage('Checkout') {
                checkout scm
            }

            stage('[Terraform] Destroy') {
                folioHelm.withKubeConfig(params.CLUSTER) {
                    if ((kubectl.checkNamespaceExistence('ecs-snapshot')) == 'ecs-snapshot') {
                        folioPrint.colored("ecs-snapshot environment exists!\nproceeding with destroy operation...", "red")
                        try {
                            build job: '/folioRancher/folioNamespaceTools/deleteNamespace',
                                    parameters: [string(name: 'CLUSTER', value: 'folio-testing'),
                                                 string(name: 'NAMESPACE', value: 'ecs-snapshot'),
                                                 booleanParam(name: 'RW_SPLIT', value: false),
                                                 string(name: 'POSTGRESQL', value: 'built-in'),
                                                 string(name: 'KAFKA', value: 'built-in'),
                                                 string(name: 'OPENSEARCH', value: 'aws'),
                                                 string(name: 'S3_BUCKET', value: 'built-in'),
                                                 string(name: 'AGENT', value: 'jenkins-agent-java17'),
                                                 booleanParam(name: 'REFRESH_PARAMETERS', value: false)]
                        } catch (Exception exception) {
                            folioPrint.colored("Existing environment has not been destroyed, error: ${exception.getMessage()}", "red")
                        }
                    } else {
                        folioPrint.colored("ecs-snapshot environment does not exist...\ncontinuing to work...", "green")
                    }
                }
            }

            stage('[Terraform] Provision') {
                folioTerraformFlow.manageNamespace('apply', tfConfig)
            }

            stage('[DB and Index] Restore') {
                folioPrint.colored("Restoring indices...", "green")
                withCredentials([usernamePassword(credentialsId: 'elastic', passwordVariable: 'es_password', usernameVariable: 'es_username')]) {
                    folioEcsIndices.prepareEcsIndices("${env.es_username}", "${env.es_password}")
                }

                folioHelm.withKubeConfig(params.CLUSTER) {
                    folioPrint.colored("Restoring psql ecs dump...\nEstimated duration: ~ 2 hours", "green")
                    psqlDumpMethods.restoreHelmData("psql-restore", "psql-dump", "1.0.5", "ecs-snapshot-users",
                            "ecs-snapshot", Constants.PSQL_DUMP_BACKUPS_BUCKET_NAME,
                            "ecs-snapshot", "${params.NAMESPACE}")
                }
            }

            stage('Restore reparation') {
                folioHelm.withK8sClient {
                    namespace.getModules().setInstallJson(new Tools(this)
                            .jsonParse(awscli.getS3FileContent("${installJsonS3Path}" + "install.json")))
                    namespace.setOkapiVersion(common.getOkapiVersion(namespace.getModules().getInstallJson()))
                }
            }

            folioDeployFlow.restore(namespace)

            stage('New modules deploy') {
                folioHelm.withKubeConfig(namespace.getClusterName()) {
                    updateJson = new GitHubUtility(this).getEnableList('platform-complete', 'snapshot')

                    namespace.getModules().setInstallJson(updateJson)
                    namespace.setEnableConsortia(true, false)

                    println(namespace.getModules().getInstallJson()) // for postman t-shooting purpose

                    List institutional = ['cs00000int', 'cs00000int_0001', 'cs00000int_0002', 'cs00000int_0003', 'cs00000int_0004', 'cs00000int_0005']

                    institutional.each { institute ->
                        OkapiTenant okapiTenant = new OkapiTenant(institute)
                                .withInstallJson(namespace.getModules().getInstallJson())
                                .withInstallRequestParams(installRequestParams)
                        if (institute != 'cs00000int') {
                            okapiTenant.getModules().removeModule('folio_consortia-settings')
                        }
                        namespace.addTenant(okapiTenant)
                    }

                    folioHelm.deployFolioModulesParallel(namespace, namespace.getModules().getBackendModules(), false, namespace.getDefaultTenantId())
                    folioEdge.renderEphemeralProperties(namespace)
                    folioHelm.deployFolioModulesParallel(namespace, namespace.getModules().getEdgeModules(), false, namespace.getDefaultTenantId())

                    sleep time: 5, unit: 'MINUTES' //Timeout before enabling new snapshot modules

                    main.preInstall(namespace.getModules().getInstallJson(), namespace.getModules().getDiscoveryList())
                    main.update(namespace.getTenants())
                }
            }

            stage('Build and deploy UI') {
                String commitHash = ''
                String folioBranch = ''

                folioHelm.withK8sClient {
                    namespace.getModules().setInstallJson(updateJson)
                    folioBranch = 'snapshot'
                    commitHash = common.getLastCommitHash("platform-complete", "snapshot")
                    namespace.setEnableConsortia(true)
                }

                TenantUi tenantUi = new TenantUi("${params.CLUSTER}-${params.NAMESPACE}", commitHash, folioBranch)

                namespace.addTenant(new OkapiTenant(defaultTenantId)
                        .withInstallRequestParams(installRequestParams)
                        .withConfiguration(new OkapiConfig())
                        .withTenantUi(tenantUi.clone()))

                namespace.getTenants().each { tenantId, tenant ->
                    if (tenant.getTenantUi()) {
                        TenantUi ui = tenant.getTenantUi()
                        def jobParameters = [tenant_id  : ui.getTenantId(),
                                             custom_hash: ui.getHash(),
                                             custom_url : "https://${namespace.getDomains()['okapi']}",
                                             custom_tag : ui.getTag(),
                                             consortia  : true]
                        uiBuild(jobParameters)
                        folioHelm.withKubeConfig(namespace.getClusterName()) {
                            folioHelm.deployFolioModule(namespace, 'ui-bundle', ui.getTag(), false, ui.getTenantId())
                        }
                    }
                }
            }
            stage('The rest components placeholder') {
                // GreenMail
                // LDP
                // Mock server
                // etc.
            }

        } catch (e) {
            println "Caught exception: ${e}"
            slackNotifications.sendPipelineFailSlackNotification("#rancher_tests_notifications")
            error(e.getMessage())
        } finally {
            stage('Notify and Cleanup') {
                slackNotifications.sendPipelineFailSlackNotification("#rancher_tests_notifications")
                cleanWs notFailBuild: true
            }
        }
    }
}
