#!groovy
import org.folio.Constants
import org.folio.models.InstallRequestParams
import org.folio.models.OkapiConfig
import org.folio.models.OkapiTenant
import org.folio.models.OkapiTenantConsortia
import org.folio.models.RancherNamespace
import org.folio.models.TenantUi
import org.folio.models.TerraformConfig
import org.folio.utilities.Tools
import org.jenkinsci.plugins.workflow.libs.Library

@Library('pipelines-shared-library@RANCHER-1216') _

CONFIG_BRANCH = 'RANCHER-1216'

properties([
        buildDiscarder(logRotator(numToKeepStr: '30')),
        disableConcurrentBuilds(),
        parameters([
                folioParameters.cluster(),
                folioParameters.namespace(),
                folioParameters.configType(),
                booleanParam(name: 'CONSORTIA', defaultValue: false, description: '(Optional) Set to true to enable consortium'),
                booleanParam(name: 'RW_SPLIT', defaultValue: false, description: '(Optional) Set to true to enable Read/Write split'),
                folioParameters.pgType(),
                folioParameters.kafkaType(),
                folioParameters.opensearchType(['aws']),
                folioParameters.s3Type(),
                folioParameters.agent(),
                folioParameters.refreshParameters()]),
//        pipelineTriggers([parameterizedCron("30 01 * * 1-5 %CLUSTER=folio-testing;NAMESPACE=esc-snapshot;CONFIG_TYPE=testing;CONSORTIA=true;" +
//                "POSTGRESQL=built-in;KAFKA=built-in;OPENSEARCH=aws;S3_BUCKET=built-in,AGENT=jenkins-agent-java17")])
])

if (params.REFRESH_PARAMETERS) {
    currentBuild.result = 'ABORTED'
    return
}

String defaultTenantId = 'cs00000int'

TerraformConfig tfConfig = new TerraformConfig('terraform/rancher/project')
        .withWorkspace("${params.CLUSTER}-${params.NAMESPACE}")

tfConfig.addVar('rancher_cluster_name', params.CLUSTER)
tfConfig.addVar('rancher_project_name', params.NAMESPACE)
tfConfig.addVar('tenant_id', defaultTenantId)
tfConfig.addVar('pg_password', Constants.PG_ROOT_DEFAULT_PASSWORD)
tfConfig.addVar('pgadmin_password', Constants.PGADMIN_DEFAULT_PASSWORD)
tfConfig.addVar('pg_version', '12.15')
tfConfig.addVar('pg_dbname', 'folio')
tfConfig.addVar('pg_vol_size', 100)
tfConfig.addVar('pg_embedded', params.POSTGRESQL == 'built-in')
tfConfig.addVar('kafka_shared', params.KAFKA == 'built-in')
tfConfig.addVar('opensearch_shared', params.OPENSEARCH != 'built-in')
tfConfig.addVar('s3_embedded', params.S3_BUCKET == 'built-in')
tfConfig.addVar('pgadmin4', 'true')
tfConfig.addVar('enable_rw_split', params.RW_SPLIT)
tfConfig.addVar('pg_ldp_user_password', Constants.PG_LDP_DEFAULT_PASSWORD)
tfConfig.addVar('github_team_ids', folioTools.getGitHubTeamsIds("${Constants.ENVS_MEMBERS_LIST[params.NAMESPACE]},${params.MEMBERS}").collect { "\"${it}\"" })

String installJsonS3Path = "${Constants.PSQL_DUMP_BACKUPS_BUCKET_NAME}/ecs-snapshot/"
InstallRequestParams installRequestParams = new InstallRequestParams(reinstall: true)


RancherNamespace namespace = new RancherNamespace(params.CLUSTER, params.NAMESPACE)
        .withSuperTenantAdminUser()
        .withDefaultTenant(defaultTenantId)
        .withDeploymentConfigType(params.CONFIG_TYPE)


namespace.addDeploymentConfig(CONFIG_BRANCH)
namespace.setEnableRwSplit(params.RW_SPLIT)

ansiColor('xterm') {
    node(params.AGENT) {
        stage('Ini') {
            buildName "${tfConfig.getWorkspace()}-${env.BUILD_ID}"
            buildDescription "Config: ${params.CONFIG_TYPE}"
        }
        try {
            stage('Checkout') {
                checkout scm
            }

            stage('[Terraform] Destroy') {
                folioHelm.withKubeConfig(params.CLUSTER) {
                    if ((kubectl.checkNamespaceExistence('ecs-snapshot')) == 'ecs-snapshot') {
                        folioPrint.colored("ecs-snapshot environment exists!\nproceeding with destroy operation...", "red")
                        try {
                            build job: '/folioRancher/folioNamespaceTools/deleteNamespace',
                                    parameters: [string(name: 'CLUSTER', value: 'folio-testing'),
                                                 string(name: 'NAMESPACE', value: 'ecs-snapshot'),
                                                 booleanParam(name: 'RW_SPLIT', value: false),
                                                 string(name: 'POSTGRESQL', value: 'built-in'),
                                                 string(name: 'KAFKA', value: 'built-in'),
                                                 string(name: 'OPENSEARCH', value: 'aws'),
                                                 string(name: 'S3_BUCKET', value: 'built-in'),
                                                 string(name: 'AGENT', value: 'jenkins-agent-java17'),
                                                 booleanParam(name: 'REFRESH_PARAMETERS', value: false)]
                        } catch (Exception exception) {
                            folioPrint.colored("Existing environment has not been destroyed, error: ${exception.getMessage()}", "red")
                        }
                    } else {
                        folioPrint.colored("ecs-snapshot environment does not exist...\ncontinuing to work...", "green")
                    }
                }
            }

            stage('[Terraform] Provision') {
                folioTerraformFlow.manageNamespace('apply', tfConfig)
            }

            stage('[DB and Index] Restore') {
                folioHelm.withKubeConfig(params.CLUSTER) {
                    folioPrint.colored("Restoring psql ecs dump...\nEstimated duration: ~ 2 hours", "green")
                    psqlDumpMethods.restoreHelmData("psql-restore", "psql-dump", "1.0.5", "ecs-snapshot-users",
                            "ecs-snapshot", Constants.PSQL_DUMP_BACKUPS_BUCKET_NAME,
                            "ecs-snapshot", "${params.NAMESPACE}")
                }
                folioPrint.colored("Restoring indices...", "green")
                withCredentials([usernamePassword(credentialsId: 'elastic', passwordVariable: 'es_password', usernameVariable: 'es_username')]) {
                    folioEcsIndices.prepareEcsIndices("${env.es_username}", "${env.es_password}")
                }
            }

            stage('Preparation') {
                String commitHash = ''
                String folioBranch = ''

                folioHelm.withK8sClient {
                    namespace.getModules().setInstallJson(new Tools(this)
                            .jsonParse(awscli.getS3FileContent("${installJsonS3Path}" + "install.json")))
                    folioBranch = 'R2-2023-Consortia'
                    commitHash = common.getLastCommitHash("platform-complete", "R2-2023-Consortia")
                }

                namespace.setOkapiVersion(common.getOkapiVersion(namespace.getModules().getInstallJson()))
                namespace.setEnableConsortia(params.CONSORTIA)

                TenantUi tenantUi = new TenantUi("${params.CLUSTER}-${params.NAMESPACE}", commitHash, folioBranch)
                namespace.addTenant(new OkapiTenant(defaultTenantId)
                        .withConfiguration(new OkapiConfig())
                        .withTenantUi(tenantUi.clone()))
            }

            folioDeployFlow.restore(namespace)

            stage('Build and deploy UI') {
                namespace.getTenants().each { tenantId, tenant ->
                    if (tenant.getTenantUi()) {
                        TenantUi ui = tenant.getTenantUi()
                        def jobParameters = [
                                tenant_id  : ui.getTenantId(),
                                custom_hash: ui.getHash(),
                                custom_url : "https://${namespace.getDomains()['okapi']}",
                                custom_tag : ui.getTag(),
                                consortia  : tenant instanceof OkapiTenantConsortia
                        ]
                        uiBuild(jobParameters)
                        folioHelm.withKubeConfig(namespace.getClusterName()) {
                            folioHelm.deployFolioModule(namespace, 'ui-bundle', ui.getTag(), false, ui.getTenantId())
                        }
                    }
                }
            }

            stage('Update to snapshot versions') {

            }

        } catch (e) {
            println "Caught exception: ${e}"
            error(e.getMessage())
        } finally {
            stage('Cleanup') {
                cleanWs notFailBuild: true
            }
        }
    }
}
